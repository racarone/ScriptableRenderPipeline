// We need N bounces given that we want to support complex light paths
#pragma max_recursion_depth 11

// HDRP include
#define SHADER_TARGET 50

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/Builtin/BuiltinData.hlsl"

// Ray tracing includes
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/ShaderVariablesRaytracing.hlsl"

// Path tracing includes
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/PathTracing/Shaders/PathTracingIntersection.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/PathTracing/Shaders/PathTracingSampling.hlsl"

// Input(s)
float4x4 _PixelCoordToViewDirWS;
int      _RaytracingCameraSkyEnabled;
float3   _RaytracingCameraClearColor;

// Output(s)
RWTexture2D<float4> _CameraColorTextureRW;
RWTexture2D<float4> _AccumulatedFrameTexture;

void AddConvergenceCue(uint2 pixelCoord, uint sampleCount, inout float3 color)
{
    // If we reached 100%, do not display the bar anymore
    if (sampleCount >= _RaytracingNumSamples)
        return;

    uint width, height;
    _CameraColorTextureRW.GetDimensions(width, height);

    // Change color only in a region corresponding to a progress bar, at the bottom of the screen
    if (pixelCoord.y < 4 && (float)pixelCoord.x / width <= (float)sampleCount / _RaytracingNumSamples)
    {
        float lum = Luminance(color);

        if (lum > 1.0)
        {
            color /= lum;
            lum = 1.0;
        }

        // Make dark color brighter, and vice versa
        color += lum > 0.5 ? -0.5 * lum : 0.05 + 0.5 * lum;
    }
}

[shader("miss")]
void MissCamera(inout PathIntersection pathIntersection : SV_RayPayload)
{
    // If the _RaytracingCameraClearColor content is positive, we override the camera sky display with a bg color
    pathIntersection.value = _EnvLightSkyEnabled && _RaytracingCameraSkyEnabled ?
        SAMPLE_TEXTURECUBE_ARRAY_LOD(_SkyTexture, s_trilinear_clamp_sampler, WorldRayDirection(), 0.0, 0) : _RaytracingCameraClearColor * GetInverseCurrentExposureMultiplier();
}

[shader("miss")]
void MissLight(inout PathIntersection pathIntersection : SV_RayPayload)
{
}

[shader("miss")]
void MissMaterial(inout PathIntersection pathIntersection : SV_RayPayload)
{
    pathIntersection.value = _EnvLightSkyEnabled && (_RaytracingMaxRecursion - pathIntersection.remainingDepth) >= _RaytracingMinRecursion ?
        SAMPLE_TEXTURECUBE_ARRAY_LOD(_SkyTexture, s_trilinear_clamp_sampler, WorldRayDirection(), 0.0, 0) : 0.0;
}

[shader("raygeneration")]
void RayGen()
{
    uint2 LaunchIndex = DispatchRaysIndex();

    // Get the current pixel coordinates
    uint2 currentPixelCoord = uint2(LaunchIndex.x, LaunchIndex.y);

    // Have we reached max sampling?
    uint sampleCount = _RaytracingFrameIndex;
    if (sampleCount >= _RaytracingNumSamples)
    {
        _CameraColorTextureRW[currentPixelCoord] = float4(_AccumulatedFrameTexture[currentPixelCoord].xyz * GetCurrentExposureMultiplier(), 1.0);
        return;
    }

    // Jitter them (we use 4x10 dimensions of our sequence during path tracing atm, so pick the next available ones)
    float3 jitteredPixelCoord = float3(currentPixelCoord, 1.0);
    jitteredPixelCoord.x += GetSample(currentPixelCoord, _RaytracingFrameIndex, 40);
    jitteredPixelCoord.y += GetSample(currentPixelCoord, _RaytracingFrameIndex, 41);

    // Compute the ray direction, from those coordinates
    float3 directionWS = -normalize(mul(jitteredPixelCoord, (float3x3)_PixelCoordToViewDirWS));

    // Create the ray descriptor for this pixel
    RayDesc rayDescriptor;
    rayDescriptor.Origin = _WorldSpaceCameraPos;
    rayDescriptor.Direction = directionWS;
    rayDescriptor.TMin = _RaytracingCameraNearPlane;
    rayDescriptor.TMax = FLT_INF;

    // Create and init the PathIntersection structure for this
    PathIntersection pathIntersection;
    pathIntersection.value = 1.0;
    pathIntersection.remainingDepth = _RaytracingMaxRecursion;
    pathIntersection.pixelCoord = currentPixelCoord;
    pathIntersection.maxRoughness = 0.001;

    // In order to achieve filtering for the textures, we need to compute the spread angle of the pixel
    pathIntersection.cone.spreadAngle = _RaytracingPixelSpreadAngle;
    pathIntersection.cone.width = 0.0;

    // Evaluate the ray intersection
    TraceRay(_RaytracingAccelerationStructure, RAY_FLAG_CULL_BACK_FACING_TRIANGLES, RAYTRACINGRENDERERFLAG_PATH_TRACING, 0, 1, 0, rayDescriptor, pathIntersection);

    // Accumulate the result
    if (sampleCount++)
        pathIntersection.value = (_AccumulatedFrameTexture[currentPixelCoord].xyz * (sampleCount - 1) + pathIntersection.value) / sampleCount;
    _AccumulatedFrameTexture[currentPixelCoord] = float4(pathIntersection.value, 1.0);

    // Apply exposure modifier
    pathIntersection.value *= GetCurrentExposureMultiplier();

    // Add a little convergence cue to our result
    AddConvergenceCue(currentPixelCoord, sampleCount, pathIntersection.value);

    _CameraColorTextureRW[currentPixelCoord] = float4(pathIntersection.value, 1.0);
}

// This should never be called, return magenta just in case
[shader("closesthit")]
void ClosestHit(inout PathIntersection pathIntersection : SV_RayPayload, AttributeData attributeData : SV_IntersectionAttributes)
{
    pathIntersection.value = float3(1.0, 0.0, 0.5);
}
